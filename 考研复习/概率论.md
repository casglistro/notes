## 1. 随机事件和概率
### 1.1 事件关系和运算
1. 吸收率: 若 $A \subset B,则 A \cup B = B, A \cap B =A$
2. 交换律
3. 结合率：若 $(A \cup B) \cup C = A \cup (B \cup C), (A \cap B) \cap C = A \cap (B \cap C)$
4. 分配率: $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$, 对减，并也成立。
5. 德摩根律: $\overline{A \cap B}= \bar{A} \cup \bar{B},\overline{A \cup B} = \bar{A} \cap \bar{B}$
其他:
$AB=\overline{A} \ \overline{B},A+BC=(A+B)(A+C),A-B=A \overline{B}=A-AB$
$AB \cup \overline{AB} = \omega \to A \cup B = \omega$
也可以使用**韦恩图**。
### 1.2 概率公式
$P(A|B)=\dfrac{P(AB)}{P(B)},P(\overline{B}|A)=1-P(B|A),P[(B-C)|A]=P(B|A)-P(BC|A)$
$P(A+B)=P(A)+P(B)-P(AB)$
$P(A_{1}A_{2}\dots A_{n})=P(A_{1})P(A_{2}|A_{1})P(A_{3}|A_{1}A_{2})\dots P(A_{n}|A_{1}A_{2}\dots A_{n-1})$
全概率公式：达成一个事件有 $n$ 条路，那么概率就是从起点走到中间点，再从中间点走到终点的概率乘积的和。
$$
P(B)=\sum^{n}_{i=1}P(A_{i})P(B|A_{i})
$$
贝叶斯公式:
从某条路走过的概率:
$$
P(A_{j}|B)= \dfrac{P(A_{j})P(B|A_{j})}{\sum^{n}_{i=1}P(A_{i})P(B|A_{i})}
$$
### 1.3 独立性
$AB 独立 \iff P(AB)=P(A)P(B) \iff   \bar{A}B 独立 \iff  A\bar{B}独立 \iff  \bar{A} \bar{B} 独立$
独立不具有传递性，两两独立不能推出全都独立。
不可能事件和必然事件和任意事件都独立。
对独立事件组不含相同事件运算，得到的事件组仍然独立。
$A,B,C,D 独立 \implies A,BC 独立 \implies AD, B-C独立$

## 2. 一维随机变量及其分布
分部函数的性质：
1. 单调不减
2. 右连续，也就是 $\lim_{ x \to x^-_{0} }F(x)=F(x_{0}+0)=F(x_{0})$
3. $F(-\infty)=0,F(+\infty)=1$
分部函数求概率
$P\left\{ X \leq a \right\}=F(a),P\left\{ X<a \right\}=F(a-0),P\left\{ X=a \right\}=F(a)-F(a-0)$
$P\left\{ a \leq X \leq b \right\}=F(b)-F(a-0)$

### 2.1 离散型随机变量和连续性随机变量
离散型随机变量只取有限个值。
连续性随机变量分布函数可以表示为
$$
F(x)=\int^{x}_{-\infty}f(t)dt
$$
而 $f(x)$ 是它的概率密度函数，有 $\int^{\infty}_{-\infty}f(x)=1$。
连续性随机函数在单点无概率。

### 2.2 常见的随机变量分布类型
1. $0-1$ 分布 $B(1,p)$
2. 二项分布 $B(n,p)$
$$
P\left\{ X=k \right\}=C^k_{n}p^k(1-p)^{n-k} 
$$
3. 泊松分部 $P(\lambda)$
$$
P\left\{ X=k \right\} =\dfrac{\lambda^k}{k!}e^{-\lambda} 
$$
泊松定理：当 $X \sim B(n,p),n很大，p很小，np适中时，使用泊松分部近似二项分布$。
4. 几何分部
$$
P = \left\{ X=k \right\}=(1-p)^{k-1}p 
$$
几何分布有无记忆性。
其意义是，实验了 $k$ 次，最后一次成功的概率。
5. 超几何分布 $H(n,N,M)$
一般使用二项分布近似。
6. 均匀分布 $U(a,b)$
$$
f(x)= \left\{\begin{align}\dfrac{1}{b-a},a<x<b \\
0, 其他
\end{align}\right.
$$
7. 指数分部 $E(\lambda)$
$$
f(x)= \left\{\begin{align} \lambda e^{-\lambda x},x>0 \\
0, 其他
\end{align}\right.
$$
指数分布有无记忆性，有 $P\left\{ X \geq S+T | X \geq S\right\}=P\left\{ X\ge T \right\}$。
8. 正态分布 $N(\lambda,\sigma^2)$
$$
f(x)= \dfrac{1}{\sqrt{ 2\pi }\sigma} e^{-\dfrac{1}{2}(\dfrac{x-\mu}{\sigma})^2}
$$
$N(0,1)$ 是标准正态分布。其分部函数是 $\phi(x)=\dfrac{1}{\sqrt{ 2\pi }}\int^{x}_{-\infty}e^{-\dfrac{t^2}{2}}dt$
对于 $X \sim N(\mu, \sigma^2),\dfrac{x-\mu}{\sigma} \sim N(0,1)$，所以对于正态分部题最重要的步骤是先标准化。

### 2.3 一维随机变量函数的分布
常用分布函数法
已知 $X$ 的分布 $F(X)$
1. $2X$ 的分布
$$
Z=2X,F_{z}(Z)=P \left\{ Z\leq z \right\}=P \left\{ 2X  \leq z\right\}=P\left\{ X \leq \dfrac{z}{2} \right\}   
$$
由此换成已知 $X$ 的分布。
2. $X^2$ 的分布
$$
Z=X^2,F_{z}(Z)=P\left\{ Z\leq z \right\}=P\left\{ X^2\leq z \right\}=P \left\{ -\sqrt{ z } \leq X \leq \sqrt{ z } \right\}   
$$
处理方法都是一样的。

## 3 多维随机变量及其分布
联合分布函数依然有单调性，右连续，非负，有界。
边缘分布函数
$$
F_{x}(X)=P \left\{ X\leq x \right\}=P \left\{ X\leq x, Y < +\infty \right\}=\lim_{ y \to \infty } F(x,y)=F(x,+\infty)   
$$
$$
F_Y(y)=F(+\infty,y)
$$
条件分布函数
$$
P\left\{ X=x_{i} | Y=y_{i} \right\}=\dfrac{P_{ij}}{P_{kj}} 
$$
其中 $k$ 是一个特定的值。
另外，有边缘分布函数乘以条件分布函数等于联合分布函数。

对于连续随机变量
联合分布函数
$$
F(x,y)=\int^{y}_{-\infty}dv \int^{x}_{-\infty}f(u,v)du
$$
其中 $f(u,v)$ 是其概率密度函数函数。
有
$$
f(x,y)\geq 0, \int^{+\infty}_{-\infty} dy \int^{+\infty}_{-\infty} f(x,y)dx=1
$$

边缘概率密度
$$
f_{X}(x)=\int^{+\infty}_{-\infty} f(x,y)dy, f_{Y}(y)=\int^{+\infty}_{-\infty}f(x,y)dx
$$
注意这里积分变量是另外一个。

条件概率密度
$X=x$ 条件下的条件概率密度
$$
f_{Y|X}(y|x)=\dfrac{f(x,y)}{f_{X}(x)}
$$
同理定义 $Y=y$ 下的条件概率密度
$$
f_{X|Y}(x|y)=\dfrac{f(x,y)}{f_{Y}(y)}
$$
同样也有 $f(x,y)=f_{X}(x)f_{Y|X}(y|x)=f_{Y}(y)f_{X|Y}(x|y)$。

### 3.1 常见的二维分布
1. 二维均匀分布
$$
f(x,y)=\left\{\begin{align} \dfrac{1}{S_{P}},(x,y) \in D \\
0,  其他
\end{align}\right.
$$
2. 二维正态分布
记为 $(X_{1},X_{2}) \sim N(\mu_{1},\mu_{2};\sigma^2_{1},\sigma_{2}^2;\rho)$
其中第五个参数是协方差，如果为 $0$ 说明这两个正态分布相互独立。
如果 $(X_{1},X_{2}) \sim N$, 则 $k_{1}X_{1}+k_{2}X_{2} \sim N$, $k_{1},k_{2}$ 是不全为 $0$ 的常数。


### 3.2 随机变量的相互独立性
独立性的判别：
$$
F(x,y)=F_{X}(x)F_{Y}(y)或f(x,y)=f_{X}(x)f_{Y}(y)
$$
不独立的判别:
任意取值不满足上式即可，一般来说，独立的条件是**概率密度函数区域是矩形且函数表达式可分离**。

### 3.3 多维随机变量函数的分布
如果是两个离散型，直接使用分布列求解，
如果是一个离散型一个连续型，根据分布列化为几个连续型随机变量，再分别求解后使用全概率公式得到分布。
如果是两个连续型：
1. 使用分布函数法
已知 $f(x,y)$
求 $Z=X+Y$ 的分布
$$
P\left\{ Z \leq z\right\} =P \left\{ X+Y \leq z \right\} = \iint_{x+y\leq z}f(x,y)dxdy
$$
求 $g(X,Y)$ 的分布
$$
F(z)=\iint_{g(x,y)\leq z}f(x,y)dxdy
$$
再求导得到概率密度。

2 使用卷积公式法
口诀是**积谁不换谁，换完求偏导**
求 $Z=X+Y$ 的分布
$$
f_{z}(Z)=\int^{+\infty}_{-\infty}f(x,z-x)\left| \dfrac{\partial(z-x)}{\partial z} \right| dx=\int^{\infty}_{-\infty}f(z-y,y) \left| \dfrac{\partial (z-y)}{\partial z} \right| 
$$
求 $Z=\dfrac{X}{Y}$ 的分布
$$
f_{z}(Z)=\int^{+\infty}_{-\infty} f(yz,y) \left| \dfrac{\partial (yz)}{\partial z} \right|  dy
$$
注意是对 $z$ 求偏导。
求 $\mathrm{\max}(X,Y)$ 分布
$\max(X,Y)\leq z$ 也就是两者的较小者比 $z$ 小
$$
F(z)=P \left\{ x\leq z,Y\leq z \right\}=F(z,z) 
$$
求 $\min(X,Y)$ 分布
$\min(X,Y)\leq z$ 也就是两者的较大值比 $z$ 小
$$
F(z)=P \left\{ \left\{ X \leq z \right\} \cup \left\{ Y\leq z \right\}   \right\}=F_{X}(z)+F_{Y}(z)-F(z,z) 
$$


### 3.4 常见分布的可加性
$X \sim B(n,p), Y \sim (m,p) \to X+Y \sim B(n+m,p)$
$X \sim P(\lambda_{1}), Y \sim P(\lambda_{2}) \to X+Y \sim P(\lambda_{1}+\lambda_{2})$
$X \sim N(\mu_{1},\sigma_{1}^2), Y \sim N(\mu_{2},\sigma_{2}^2), \to X+Y \sim N(\mu_{1}+\mu_{2},\sigma_{1}^2+\sigma_{2}^2), X-Y \sim N(\mu_{1}-\mu_{2}, \sigma_{1}^2+\sigma_{2}^2)$
$X \sim \chi^2(n),Y \sim \chi^2(m) \to X+Y \sim \chi^2(n+m)$

## 4. 随机变量的数字特征
期望:
$$
E(g(x))=\int^{+\infty}_{-\infty}g(x)f(x)dx
$$
性质:
$E(a)=a,E(EX)=EX$
$E(aX+bY)=aEX+bEY, E \left( \sum^{n}_{i=1}a_{i}X_{i} \right)=\sum_{i=1}^n a_{i}EX_{}i$
若 $X,Y$ 相互独立，$E(XY)=EXEY$, 反之不一定成立，实际上 $E(XY)=E(X)E(Y)+Cov(X,Y)$
另外，期望中的函数满足分配率，由定义可知这是很显然的。
$E\left[ (X-EX)(Y-EY) \right]=E \left[ XY-XEY-YEX+EXEY \right]=E \left[ XY \right]-EXEY-EXEY+EXEY=E \left[ XY \right]-EXEY$
方差
$$
D(X)=E \left[ (X-EX)^2 \right] =E(X^2)-(EX)^2
$$
有一些期望需要使用方差计算。

性质
$D(aX+b)=a^2D(X)$
$D(X\pm Y)=DX+DY\pm 2Cov(X,Y)$
$D \left( \sum^{n}_{i=1}a_{i}X_{i} \right)=\sum^{n}_{i=1}a^2_{i}DX_{i}+2\sum_{1 \leq i <j\leq n}a_{i}a_{j}Cov(X_{i},X_{j})$

### 4.1 常见分布的期望和方差
1. $0-1$ 分布
$E(X)=p,D(X)=p(1-p)$
2. 二项分布
$E(X)=np,D(X)=np(1-p)$
3. 泊松分布
$E(x)=\lambda,D(x)=\lambda$
4. 几何分布
$E(x)=\dfrac{1}{p},D(x)=\dfrac{1-p}{p^2}$
5. 均匀分布
$E(x)=\dfrac{a+b}{2},D(x)=\dfrac{(a-b)^2}{12}$
6. 指数分布
$E(x)=\dfrac{1}{\lambda},D(x)=\dfrac{1}{\lambda^2}$

### 4.2 二维随机变量的数字特征
$$
E \left[ g(X,Y) \right] = \int^{+\infty}_{-\infty} \int^{+\infty}_{-\infty}g(x,y)f(x,y)dxdy 
$$

协方差和相关系数
$$
Cov(X,Y)=E \left[ (X-EX)(Y-EY) \right] = E(XY)-EXEY
$$
$$
\begin{align}

\end{align}
$$
相关系数定义为
$$
\rho_{XY}=\dfrac{Cov(X,Y)}{\sqrt{ DX } \sqrt{ DY }}
$$
如果为 $0$ 称为不相关，如果不相关，有协方差为 $0$, 但是**不代表独立**。

性质
$Cov(X,Y)=Cov(Y,X)$
$Cov(aX,bY)=abCov(X,Y)$
$Cov(X_{1}+X_{2},Y_{1}+Y_{2})=\sum_{1 \leq i \leq 2, 1\leq j \leq 2}Cov(X_{i},Y_{j})$，自由两两组合。
$\rho_{XY}=1$ 说明 $Y和aX+b$ 同分布，如果 $\rho > 1$, 则 $a>0$, 否则 $a<0$。

不相关性的判别
$$
\rho_{XY}=0 \iff Cov(X,Y)=0 \iff E(XY)=EXEY \iff D(X\pm Y)= DX+DY
$$
如果独立一定不相关，但是反之不一定成立。

###  4.3 切比雪夫不等式
对任意 $\epsilon > 0$ 有
$$
P \left\{  |X-EX| \geq \epsilon \right\} \leq \dfrac{DX}{\epsilon^2} 
$$
其意义是，偏离期望的距离越高，概率越小。


## 5. 大数定律和中心极限定理
1. 依概率收敛
设随机变量 $X$ 和随机变量序列 $\left\{ X_{n} \right\}$, 如果对任意 $\epsilon>0$,
有
$$
\lim_{ n \to \infty } P \left\{ |X_{n}-X| \geq \epsilon \right\}=0 \ or \ \lim_{ n \to \infty } P \left\{ |X_{n}-X| < \epsilon\right\}=1    
$$
就说随机变量序列依概率收敛于 $X$。
记为
$$
X_{n} \xrightarrow{P} X(n \to \infty)
$$
2. 大数定律
切比雪夫大数定律
$\left\{ X_{i} \right\}$ 是**相互独立**的随机变量序列，**方差相同且有上界**，则样本均值依概率收敛于期望均值
$$
\dfrac{1}{n} \sum_{i=1}^n X_{i} \xrightarrow{P} \dfrac{1}{n} \sum^{n}_{i=1} EX_{i} 
$$
伯努利大数定律
随机变量 $X$ 满足二项分布 $B(n,p)$, 设 $\mu_{n}$ 是事件 $A$ 发生次数，则有 
$$
\dfrac{u_{n}}{n} \xrightarrow{P} p
$$
辛钦大数定律
随机序列 $\left\{ X_{n} \right\}$ 是**独立同分布**，如果期望存在， 则样本均值依概率收敛于期望。
$$
\dfrac{1}{n} \sum^{n}_{i=1} X_{i} \xrightarrow{P} \mu
$$

总结： 伯努利是二项分布，切比雪夫是来自不同的独立序列，方差都一样且有上界，辛钦是独立同分布。
3. 中心极限定理
列维-林德伯格定理
假设 $\left\{ X_{n} \right\}$ 是**独立同分布**的随机变量序列，
设 $EX_{i}=\mu,DX_{i}=\sigma^2$
当 $n$ 很大时，随机变量的和 $\sum^{n}_{i=1}X_{i}$ 近似服从正态分布 $N(n \mu, n \sigma^2)$ 。
也就是 
$$
\dfrac{\sum^{n}_{i=1}X_{i}-n \mu}{\sqrt{  n } \sigma} \sim N(0,1)
$$

拉普拉斯定理
设随机变量 $Y_{n} \sim B(n,p)$
则有随机变量的和 $\sum^{n}_{i=1}Y_{i}$ 服从正态分布 $N(np,np(1-p))$。

## 6. 数理统计
### 6.1 统计量及其分布
$X_{1},X_{2},\dots,X_{n}$ 是来自总体的一个样本，$g(x_{1},x_{2},x_{3},\dots,x_{n})$ 是 $n$ 元函数，如果其中不含有任何未知参数，则是统计量。

常用统计量
1. 样本均值 $\bar{X}=\dfrac{1}{n}\sum^{n}_{i=1}X_{i}$
2. 样本方差 $S^2=\dfrac{1}{n-1} \sum^{n}_{i=1}(X_{i}-\bar{X})^2$
3. 样本 $k$ 阶原点矩 $A_{k}=\dfrac{1}{n} \sum^{n}_{i=1} X_{i}^k$
4. 样本 $k$ 阶中心矩 $B_{k}=\dfrac{1}{n} \sum^{n}_{i=1} (X_{i}-\bar{X})^k$
性质
$E \bar{X}=EX=\mu, D \bar{X}=\dfrac{1}{n} DX=\dfrac{\sigma^2}{n}, E(S^2)=DX=\sigma^2$ 

注:
样本方差 $S^2$ 是 $\sigma^2$ 的无偏估计，但是 $\dfrac{1}{n}\sum^{n}_{i=1}(X_{i}- \bar{X})^2$ 不是无偏估计。
因为已知均值 $\bar{X}$ 固定，所以 $X_{n}$ 可以由 $X_{1},\dots,X_{n-1}$ 线性表出，因此 $X_{n}$ 对自由度无贡献，所以自由度是 $n-1$。

### 6.2 三大分布
1. $\chi^2$ 分布
若随机变量 $X_{1},X_{2},\dots,X_{n}$ 相互独立且服从标准正态分布，则随机变量 $X=\sum^{n}_{i=1}X_{i}^2$ 服从自由度为 $n$ 的 $\chi^2$ 分布，$X \sim \chi^2(n)$。
性质
$X \sim \chi^2(n), EX=n,DX=2n$
$X_{1} \sim X^2(n), X_{2} \sim \chi^2(m) \to X_{1}+X_{2} \sim \chi^2(n+m)$
2. $t$ 分布
设 $X \sim N(0,1), Y \sim \chi^2(n)$, 且 $X,Y$ 相互独立，则 $t=\dfrac{X}{\sqrt{ \dfrac{Y}{n} }}$ 服从自由度为 $n$ 的 $t$ 分布，$t \sim t(n)$。
图像关于 $y$ 对称，因此 $t_{1-\alpha}(n)=-t_{\alpha}(n)$。
3. $F$ 分布
设 $X \sim \chi^2(n_{1}),Y \sim \chi^2(n_{2})$, $X,Y$ 相互独立，则 $F=\dfrac{\dfrac{X}{n_{1}}}{\dfrac{Y}{n_{2}}}$ 服从自由度为 $(n_{1},n_{2})$ 的 $F$ 分布，$F \sim F(n_{1},n_{2})$。
性质
$F \sim F(n_{1},n_{2}) \to \dfrac{1}{F} \sim F_{2}(n_{2},n_{1})$
$F_{1-\alpha}(n_{1},n_{2})=\dfrac{1}{F_{\alpha}(n_{2},n_{1})}$ 
$t \sim t(n) \to t^2 \sim F(1,n)$

### 6.3 正态总体条件下的常用结论
设 $X_{1},X_{2},\dots,X_{n}$ 是来自正态总体的一个样本，则
1. $\bar{X} \sim N(\mu, \dfrac{\sigma}{n^2})$
2. $\dfrac{1}{\sigma^2}\sum^{n}_{i=1}(X_{i}-\mu)^2 \sim \chi^2(n)$
3. $\dfrac{(n-1)S^2}{\sigma^2}=\sum^{n}_{i=1}(\dfrac{X_{i}-\bar{X}}{\sigma}) \sim \chi^2(n-1)$
4. $\bar{X}和S^2$ 相互独立（仅在正态总体），$\dfrac{\sqrt{ n }(\bar{X}- \mu)}{S} \sim t(n-1) \to \dfrac{n(\bar{X}-\mu)^2}{S^2}\sim F(1,n-1)$

### 6.4 参数的点估计
1. 矩估计
对于一个参数：
使用一阶矩有 $\bar{X}=EX$, 如果不可使用则用二阶矩建立 $\dfrac{1}{n}\sum X^2_{i}=E(X^2)$
对于两个参数：
用一阶矩和二阶矩建立方程。
2. 最大似然估计
写似然函数 $\Uppi^n_{i=1}f(x_{i}; \theta)$ (意思是把所有样本取值的概率乘起来即可), 然后取对数后求出驻点，然后用驻点和单调性判断。
3. 估计量的评价标准
无偏性: $E \hat{\theta}=\theta$, 则为无偏估计。
有效性: 方差更小的更有效, $D \hat{\theta_{1}}<D \hat{\theta}_{2}$。
相合性: 有 $\hat{\theta} \xrightarrow{P} \theta$, 则是相合估计。(切比雪夫不等式或者辛钦大数定律)。

### 6.5 参数的区间估计
1. $\sigma^2$ 已知，$\mu$:
使用 $\dfrac{\bar{X}-\mu}{\sigma \sqrt{ n }} \sim N(0,1)$
2. $\sigma^2$ 未知，$\mu$:
使用 $\dfrac{\sqrt{ n }(\bar{X}-\mu)}{S} \sim t(n-1)$
3. $\mu$ 已知，$\sigma^2$ :
使用 $\sum^{n}_{i=1}(\dfrac{X_{i}-\mu}{\sigma}) \sim \chi^2(n)$
4. $\mu$ 未知，$\sigma^2$
使用 $\dfrac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$

### 6.6 假设检验
当事件发生的概率不大于显著性水平 $\alpha$ 时，就认为是小概率事件，因此如果说，小概率事件发生了，则证明假设是错误的，应当拒绝假设。同时 $\alpha$ 就是弃真的概率。
如果检验 $H:\mu=\mu_{0}$, 则有双侧拒绝域，不能太大或者太小，如果 $H:\mu \geq \mu_{0}$, 则有单侧拒绝域，不能太小。

### 6.7 两类错误
第一类错误：弃真，若 $H_{0}$ 是真但是否定 $H_{0}$。
第二类错误：取伪，若 $H_{0}$ 不真但是接受 $H_{0}$。
